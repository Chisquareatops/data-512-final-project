{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from scipy.stats import pearsonr\n",
    "from statsmodels.graphics.regressionplots import abline_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('nhats_altered_subset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's start creating some models to examine the relatioships between various measures of disability and some indicators of social well-being.\n",
    "\n",
    "#### First, let's try a set of 6 independent variables:\n",
    "\n",
    "hearing_aid_used: whether or not a hearing aid was used\n",
    "\n",
    "pain_limits_activity: whether or not pain ever limited activity\n",
    "\n",
    "sppb_score: a simple physical performance battery score, an indicator of basic physical strength, balance, and mobility\n",
    "\n",
    "balance_score: the result of a physical test measuring balance\n",
    "\n",
    "walk_score: the result of a physical test measuring ability to walk\n",
    "\n",
    "go_outside_use_device: whether or not the individual ever uses a mobility device to go outside\n",
    "\n",
    "#### And one dependent variable\n",
    "\n",
    "go_out_enjoy: whether or not the individual ever goes out for enjoyment\n",
    "\n",
    "##### We will subset our data, remove the observations with missing values, and then build the model with StatsModels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2381, 7)\n"
     ]
    }
   ],
   "source": [
    "# First we will subset our data because there is no need to work with the whole data frame\n",
    "data_subset_1 = data[['hearing_aid_used', 'pain_limits_activity', 'sppb_score', 'balance_score', \n",
    "                      'walk_score', 'go_outside_use_device', 'go_out_enjoy']] \n",
    "\n",
    "# Next we need to get rid of incomplete observations\n",
    "# Convert -1 (the encoding for a missing value) to nan and then drop them\n",
    "data_subset_1 = data_subset_1.replace(-1, np.nan)\n",
    "data_subset_1 = data_subset_1.dropna()\n",
    "\n",
    "# Check that this has left us with a reasonable number of observations\n",
    "# We should still have over 2,000 observations that are complete in all 7 fields\n",
    "print(data_subset_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           go_out_enjoy   R-squared:                       0.111\n",
      "Model:                            OLS   Adj. R-squared:                  0.108\n",
      "Method:                 Least Squares   F-statistic:                     49.25\n",
      "Date:                Wed, 11 Dec 2019   Prob (F-statistic):           2.93e-57\n",
      "Time:                        10:54:22   Log-Likelihood:                -1232.1\n",
      "No. Observations:                2381   AIC:                             2478.\n",
      "Df Residuals:                    2374   BIC:                             2519.\n",
      "Df Model:                           6                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=========================================================================================\n",
      "                            coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "const                     0.5271      0.027     19.475      0.000       0.474       0.580\n",
      "hearing_aid_used          0.0733      0.021      3.503      0.000       0.032       0.114\n",
      "pain_limits_activity     -0.0096      0.018     -0.547      0.584      -0.044       0.025\n",
      "sppb_score                0.0200      0.008      2.495      0.013       0.004       0.036\n",
      "balance_score             0.0189      0.014      1.364      0.173      -0.008       0.046\n",
      "walk_score                0.0363      0.015      2.419      0.016       0.007       0.066\n",
      "go_outside_use_device    -0.0210      0.022     -0.949      0.343      -0.064       0.022\n",
      "==============================================================================\n",
      "Omnibus:                      313.027   Durbin-Watson:                   2.008\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              406.062\n",
      "Skew:                          -0.985   Prob(JB):                     6.68e-89\n",
      "Kurtosis:                       2.541   Cond. No.                         29.0\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\halli_000\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2389: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Specify the independent and dependent variables\n",
    "X = data_subset_1[['hearing_aid_used', 'pain_limits_activity', 'sppb_score', 'balance_score', \n",
    "          'walk_score','go_outside_use_device']]\n",
    "Y = data_subset_1['go_out_enjoy']\n",
    "\n",
    "# Add a constant using StatsModels\n",
    "X = sm.add_constant(X) \n",
    "\n",
    "# We will have to treat our values as floats for the model to build correctly\n",
    "model_1 = sm.OLS(Y.astype(float), X.astype(float)).fit()\n",
    " \n",
    "print_model_1 = model_1.summary()\n",
    "print(print_model_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### In this model, it looks like we have three predictors that might be worth considering: \n",
    "\n",
    "1. The use of a hearing aid seems to make it substantially more likely that a person will go out for enoyment.\n",
    "2. A higher score on the physical battery seems to make it slightly more likely.\n",
    "3. A higher walk score seems to make it slightly more likely as well. \n",
    "\n",
    "All of these coefficients have P values that are significant at at least an alpha level of .05. The R squared value of this model is not very high, but don't forget what we're looking at: the reasons that an aging person does or does not go out for enjoymet. Human behaior is complicated, and this is likely to be an extremely over-determined variable. It may not be possible to build a single comprehensible model that accounts for a high percentage of variation in whether or not individuals go out.\n",
    "\n",
    "##### Next, let's build a model to look at their interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           go_out_enjoy   R-squared:                       0.118\n",
      "Model:                            OLS   Adj. R-squared:                  0.116\n",
      "Method:                 Least Squares   F-statistic:                     45.41\n",
      "Date:                Wed, 11 Dec 2019   Prob (F-statistic):           1.18e-60\n",
      "Time:                        11:14:20   Log-Likelihood:                -1222.1\n",
      "No. Observations:                2381   AIC:                             2460.\n",
      "Df Residuals:                    2373   BIC:                             2506.\n",
      "Df Model:                           7                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==========================================================================================================\n",
      "                                             coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "Intercept                                  0.4278      0.025     17.367      0.000       0.379       0.476\n",
      "walk_score                                 0.0949      0.022      4.302      0.000       0.052       0.138\n",
      "hearing_aid_used                           0.1377      0.059      2.345      0.019       0.023       0.253\n",
      "walk_score:hearing_aid_used               -0.0314      0.048     -0.654      0.513      -0.126       0.063\n",
      "sppb_score                                 0.0440      0.007      6.692      0.000       0.031       0.057\n",
      "walk_score:sppb_score                     -0.0085      0.002     -3.811      0.000      -0.013      -0.004\n",
      "hearing_aid_used:sppb_score                0.0016      0.016      0.105      0.916      -0.029       0.032\n",
      "walk_score:hearing_aid_used:sppb_score    -0.0008      0.005     -0.156      0.876      -0.011       0.009\n",
      "==============================================================================\n",
      "Omnibus:                      299.837   Durbin-Watson:                   2.005\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              413.252\n",
      "Skew:                          -1.010   Prob(JB):                     1.83e-90\n",
      "Kurtosis:                       2.704   Cond. No.                         191.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# For ease, we will call the StatsModels formula API using smf\n",
    "# This does not change how the OLS model is created, but it lets us use R-like syntax for interactions\n",
    "model_2 = smf.ols(formula='go_out_enjoy ~ walk_score * hearing_aid_used * sppb_score', \n",
    "                 data=data_subset_1).fit()\n",
    "\n",
    "print(model_2.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### These results are really surprising!\n",
    "\n",
    "Here, we see that almost every interaction makes it slightly *less* likely that an individual will ever go out for enjoyment, even though all the predictors we focused on make it more likely individually. There are a lot of things that could be goig on, but all of them would require further study to isolate. For example, the most negative coefficiet is for the interaction between a high walk score and use of a hearing aid. Is it possible that individuals with a higher walking score tend to be younger, and more recent adopters of their hearing aids? Is the length of time an individual has used a hearing aid important? These would be great questions for a follow-up study."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next, let's try the same 6 independent variables and a new dependent variable\n",
    "\n",
    "num_in_soc_network: the number of people in an individual's social network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2289, 7)\n"
     ]
    }
   ],
   "source": [
    "# We will re-subset our data because we will need to drop observations that are missing num_in_soc_net\n",
    "# But we no longer care if a row is missing go_out_enjoy\n",
    "# We don't want to end up with fewer observations than we could have\n",
    "data_subset_2 = data[['hearing_aid_used', 'pain_limits_activity', 'sppb_score', 'balance_score', \n",
    "                      'walk_score', 'go_outside_use_device', 'num_in_soc_net']] \n",
    "\n",
    "# Next we need to get rid of incomplete observations\n",
    "# Convert -1 (the encoding for a missing value) to nan and then drop them\n",
    "data_subset_2 = data_subset_2.replace(-1, np.nan)\n",
    "data_subset_2 = data_subset_2.dropna()\n",
    "\n",
    "# Check that this has left us with a reasonable number of observations\n",
    "# We should still have over 2,000 observations that are complete in all 7 fields\n",
    "print(data_subset_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:         num_in_soc_net   R-squared:                       0.028\n",
      "Model:                            OLS   Adj. R-squared:                  0.025\n",
      "Method:                 Least Squares   F-statistic:                     10.97\n",
      "Date:                Wed, 11 Dec 2019   Prob (F-statistic):           4.41e-12\n",
      "Time:                        10:58:33   Log-Likelihood:                -3915.2\n",
      "No. Observations:                2289   AIC:                             7844.\n",
      "Df Residuals:                    2282   BIC:                             7884.\n",
      "Df Model:                           6                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=========================================================================================\n",
      "                            coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "const                     1.7522      0.092     19.059      0.000       1.572       1.932\n",
      "hearing_aid_used          0.0147      0.070      0.210      0.833      -0.122       0.152\n",
      "pain_limits_activity      0.1299      0.059      2.209      0.027       0.015       0.245\n",
      "sppb_score               -0.0200      0.026     -0.755      0.451      -0.072       0.032\n",
      "balance_score             0.1273      0.046      2.768      0.006       0.037       0.218\n",
      "walk_score                0.1685      0.050      3.384      0.001       0.071       0.266\n",
      "go_outside_use_device     0.2747      0.073      3.741      0.000       0.131       0.419\n",
      "==============================================================================\n",
      "Omnibus:                      163.196   Durbin-Watson:                   1.936\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              115.408\n",
      "Skew:                           0.443   Prob(JB):                     8.70e-26\n",
      "Kurtosis:                       2.348   Cond. No.                         29.5\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\halli_000\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2389: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# As before, specify the independent and dependent variables\n",
    "X2 = data_subset_2[['hearing_aid_used', 'pain_limits_activity', 'sppb_score', 'balance_score', \n",
    "          'walk_score','go_outside_use_device']]\n",
    "Y2 = data_subset_2['num_in_soc_net']\n",
    "\n",
    "# Add a constant using StatsModels\n",
    "X2 = sm.add_constant(X2) \n",
    "\n",
    "# We will have to treat our values as floats for the model to build correctly\n",
    "model_3 = sm.OLS(Y2.astype(float), X2.astype(float)).fit()\n",
    " \n",
    "print_model_3 = model_3.summary()\n",
    "print(print_model_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### General Observations\n",
    "\n",
    "The R-squared value for this model is extremely low, to the extent that it calls the utility of this model into question (even given some willingness to accept low R-squared values in this domain).\n",
    "\n",
    "##### In this model, it looks like we have four predictors that might be worth considering: \n",
    "\n",
    "1. Pain that sometimes limits activity seems as though it may be associated with a bigger social network! The p-value for this coefficient is the lowest of the predictors listed here, but it is still significant at the alpha=0.05 level.\n",
    "2. A higher balance score may be associated with a bigger social network.\n",
    "3. A higher walk score seems to be associated with a bigger social network. \n",
    "4. The use of a device to go outside may be associated with a bigger social network.\n",
    "\n",
    "Should we be surprised that use of an assistive device to go outside was positively correlated with a bigger social network, and in fact has the highest positive coefficient in this model? Maybe not! This may indicate that assistive devices are doing what they are supposed to do, and ameliorate the effect of mobility-related disabilities.\n",
    "\n",
    "##### Next, let's build a model to look at their interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:         num_in_soc_net   R-squared:                       0.031\n",
      "Model:                            OLS   Adj. R-squared:                  0.025\n",
      "Method:                 Least Squares   F-statistic:                     4.845\n",
      "Date:                Wed, 11 Dec 2019   Prob (F-statistic):           2.19e-09\n",
      "Time:                        11:13:47   Log-Likelihood:                -3911.7\n",
      "No. Observations:                2289   AIC:                             7855.\n",
      "Df Residuals:                    2273   BIC:                             7947.\n",
      "Df Model:                          15                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=======================================================================================================================================\n",
      "                                                                          coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "Intercept                                                               2.0298      0.261      7.775      0.000       1.518       2.542\n",
      "pain_limits_activity                                                   -0.3874      0.381     -1.016      0.310      -1.135       0.360\n",
      "balance_score                                                           0.0078      0.106      0.074      0.941      -0.200       0.215\n",
      "pain_limits_activity:balance_score                                      0.1004      0.169      0.595      0.552      -0.230       0.431\n",
      "walk_score                                                              0.0143      0.110      0.130      0.897      -0.201       0.230\n",
      "pain_limits_activity:walk_score                                         0.2503      0.164      1.524      0.128      -0.072       0.572\n",
      "balance_score:walk_score                                                0.0425      0.039      1.095      0.273      -0.034       0.118\n",
      "pain_limits_activity:balance_score:walk_score                          -0.0634      0.061     -1.035      0.301      -0.184       0.057\n",
      "go_outside_use_device                                                  -0.1060      0.323     -0.328      0.743      -0.740       0.528\n",
      "pain_limits_activity:go_outside_use_device                              0.7296      0.441      1.654      0.098      -0.135       1.595\n",
      "balance_score:go_outside_use_device                                     0.2056      0.171      1.204      0.229      -0.129       0.540\n",
      "pain_limits_activity:balance_score:go_outside_use_device               -0.2673      0.234     -1.144      0.253      -0.725       0.191\n",
      "walk_score:go_outside_use_device                                        0.0716      0.193      0.372      0.710      -0.306       0.449\n",
      "pain_limits_activity:walk_score:go_outside_use_device                  -0.2469      0.250     -0.989      0.323      -0.737       0.243\n",
      "balance_score:walk_score:go_outside_use_device                         -0.0693      0.085     -0.815      0.415      -0.236       0.097\n",
      "pain_limits_activity:balance_score:walk_score:go_outside_use_device     0.1197      0.109      1.103      0.270      -0.093       0.333\n",
      "==============================================================================\n",
      "Omnibus:                      156.689   Durbin-Watson:                   1.938\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              114.161\n",
      "Skew:                           0.445   Prob(JB):                     1.62e-25\n",
      "Kurtosis:                       2.364   Cond. No.                         228.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# We will again use the StatsModels formula API because the syntax is simpler\n",
    "model_4 = smf.ols(formula='num_in_soc_net ~ pain_limits_activity * balance_score * walk_score * go_outside_use_device', \n",
    "                 data=data_subset_2).fit()\n",
    "\n",
    "print(model_4.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This is a lot of interactions to look at, but none of them approach significance.\n",
    "\n",
    "In fact, now that we've included terms for interactions, none of the predictors we chose is significant individually, either."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now let's try the same 6 independent variables and a new dependent variable\n",
    "\n",
    "age_you_feel: the age a person feels mentally and emotionally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2195, 7)\n"
     ]
    }
   ],
   "source": [
    "# Just like before we will re-subset the data to ensure we have as many complete observations as possible\n",
    "data_subset_3 = data[['hearing_aid_used', 'pain_limits_activity', 'sppb_score', 'balance_score', \n",
    "                      'walk_score', 'go_outside_use_device', 'age_you_feel']] \n",
    "\n",
    "# Next we need to get rid of incomplete observations\n",
    "# Convert -1 (the encoding for a missing value) to nan and then drop them\n",
    "data_subset_3 = data_subset_3.replace(-1, np.nan)\n",
    "data_subset_3 = data_subset_3.dropna()\n",
    "\n",
    "# Check that this has left us with a reasonable number of observations\n",
    "# We should still have over 2,000 observations that are complete in all 7 fields\n",
    "print(data_subset_3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           age_you_feel   R-squared:                       0.081\n",
      "Model:                            OLS   Adj. R-squared:                  0.079\n",
      "Method:                 Least Squares   F-statistic:                     32.24\n",
      "Date:                Wed, 11 Dec 2019   Prob (F-statistic):           2.28e-37\n",
      "Time:                        11:33:21   Log-Likelihood:                -8851.5\n",
      "No. Observations:                2195   AIC:                         1.772e+04\n",
      "Df Residuals:                    2188   BIC:                         1.776e+04\n",
      "Df Model:                           6                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=========================================================================================\n",
      "                            coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "const                    73.6047      0.964     76.373      0.000      71.715      75.495\n",
      "hearing_aid_used          2.1716      0.730      2.975      0.003       0.740       3.603\n",
      "pain_limits_activity      0.5089      0.614      0.829      0.407      -0.694       1.712\n",
      "sppb_score               -1.0810      0.275     -3.925      0.000      -1.621      -0.541\n",
      "balance_score            -0.0962      0.480     -0.201      0.841      -1.037       0.844\n",
      "walk_score                0.3669      0.517      0.709      0.478      -0.647       1.381\n",
      "go_outside_use_device     1.6650      0.763      2.182      0.029       0.168       3.162\n",
      "==============================================================================\n",
      "Omnibus:                      338.136   Durbin-Watson:                   1.909\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              619.261\n",
      "Skew:                          -0.965   Prob(JB):                    3.38e-135\n",
      "Kurtosis:                       4.745   Cond. No.                         29.7\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\halli_000\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2389: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# As before, specify the independent and dependent variables\n",
    "X3 = data_subset_3[['hearing_aid_used', 'pain_limits_activity', 'sppb_score', 'balance_score', \n",
    "          'walk_score','go_outside_use_device']]\n",
    "Y3 = data_subset_3['age_you_feel']\n",
    "\n",
    "# Add a constant using StatsModels\n",
    "X3 = sm.add_constant(X3) \n",
    "\n",
    "# We will have to treat our values as floats for the model to build correctly\n",
    "model_5 = sm.OLS(Y3.astype(float), X3.astype(float)).fit()\n",
    " \n",
    "print_model_5 = model_5.summary()\n",
    "print(print_model_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### In this model, it looks like we have two predictors that might be worth considering: \n",
    "\n",
    "1. The use of a hearing aid seems to make individuals feel multiple years older than they might otherwise feel.\n",
    "2. A higher score on the physical battery seems to make individuals feel a bit younger.\n",
    "\n",
    "Both of these are significant at the alpha=0.01 level and the coefficients are fairly large. Let's take a second to consider the hearing aid, spoecifically. Isn't it interesting that it makes users feel older? Intuitively, that seems to make sense, but recall that hearing aid use was positively associated with going out for enjoymeny. (It was also positively associated with other markers of social wellbeing in models not illustrated here... keep experimenting with this data!) \n",
    "\n",
    "##### Now let's build a model to look at the interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           age_you_feel   R-squared:                       0.079\n",
      "Model:                            OLS   Adj. R-squared:                  0.078\n",
      "Method:                 Least Squares   F-statistic:                     62.46\n",
      "Date:                Wed, 11 Dec 2019   Prob (F-statistic):           9.56e-39\n",
      "Time:                        11:40:26   Log-Likelihood:                -8854.4\n",
      "No. Observations:                2195   AIC:                         1.772e+04\n",
      "Df Residuals:                    2191   BIC:                         1.774e+04\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===============================================================================================\n",
      "                                  coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Intercept                      75.1394      0.673    111.701      0.000      73.820      76.459\n",
      "hearing_aid_used                3.8949      1.508      2.583      0.010       0.938       6.852\n",
      "sppb_score                     -1.1029      0.097    -11.341      0.000      -1.294      -0.912\n",
      "hearing_aid_used:sppb_score    -0.2517      0.217     -1.161      0.246      -0.677       0.173\n",
      "==============================================================================\n",
      "Omnibus:                      327.880   Durbin-Watson:                   1.907\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              594.632\n",
      "Skew:                          -0.944   Prob(JB):                    7.54e-130\n",
      "Kurtosis:                       4.715   Cond. No.                         38.1\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# We will continue to use the StatsModels formula API because the syntax is simpler\n",
    "model_6 = smf.ols(formula='age_you_feel ~ hearing_aid_used * sppb_score', \n",
    "                 data=data_subset_3).fit()\n",
    "\n",
    "print(model_6.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### It doesn't look like this approach adds anything to our understanding.\n",
    "\n",
    "The interaction is not significant, but considering it has not caused a major change on the individual role of the two variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's create some models to examine the relatioships between some of the indicators of social well-being that we've considered so far.\n",
    "\n",
    "#### Let's try a set of 3 independent variables:\n",
    "\n",
    "group_activity: whether or not the individual ever participates in group activities.\n",
    "\n",
    "go_out_enjoy: whether or not the individual ever goes out for enjoyment\n",
    "\n",
    "num_in_soc_net: the number of people in the individual's social network\n",
    "\n",
    "#### And one dependent variable:\n",
    "\n",
    "age_you_feel: the age a person feels mentally and emotionally\n",
    "\n",
    "##### We will subset our data, remove the observations with missing values, and then build the model with StatsModels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfortunately our data is not perfectly clean, so we will have to recode a few values\n",
    "data = data.replace(['-7 RF'], ['-1'])\n",
    "data[['group_activity']] = data[['group_activity']].apply(pd.to_numeric) \n",
    "\n",
    "# Check that this has worked\n",
    "data.group_activity.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4456, 4)\n"
     ]
    }
   ],
   "source": [
    "# Just like before we will re-subset the data to ensure we have as many complete observations as possible\n",
    "data_subset_4 = data[['group_activity', 'go_out_enjoy', 'num_in_soc_net', 'age_you_feel']] \n",
    "\n",
    "# Next we need to get rid of incomplete observations\n",
    "# Convert -1 (the encoding for a missing value) to nan and then drop them\n",
    "data_subset_4 = data_subset_4.replace(-1, np.nan)\n",
    "data_subset_4 = data_subset_4.dropna()\n",
    "\n",
    "# Check that this has left us with a reasonable number of observations\n",
    "# In this case we have almost 4.5k observations left. Great!\n",
    "print(data_subset_4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:           age_you_feel   R-squared:                       0.012\n",
      "Model:                            OLS   Adj. R-squared:                  0.011\n",
      "Method:                 Least Squares   F-statistic:                     17.44\n",
      "Date:                Wed, 11 Dec 2019   Prob (F-statistic):           2.98e-11\n",
      "Time:                        11:58:55   Log-Likelihood:                -18322.\n",
      "No. Observations:                4456   AIC:                         3.665e+04\n",
      "Df Residuals:                    4452   BIC:                         3.668e+04\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==================================================================================\n",
      "                     coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "const             70.5476      0.572    123.329      0.000      69.426      71.669\n",
      "group_activity    -0.5557      0.469     -1.184      0.236      -1.476       0.364\n",
      "go_out_enjoy      -3.6520      0.543     -6.728      0.000      -4.716      -2.588\n",
      "num_in_soc_net     0.1101      0.168      0.655      0.512      -0.219       0.440\n",
      "==============================================================================\n",
      "Omnibus:                      275.259   Durbin-Watson:                   1.940\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              344.573\n",
      "Skew:                          -0.595   Prob(JB):                     1.50e-75\n",
      "Kurtosis:                       3.665   Cond. No.                         9.35\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\halli_000\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2389: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# As before, specify the independent and dependent variables\n",
    "X4 = data_subset_4[['group_activity', 'go_out_enjoy', 'num_in_soc_net']]\n",
    "Y4 = data_subset_4['age_you_feel']\n",
    "\n",
    "# Add a constant using StatsModels\n",
    "X4 = sm.add_constant(X4) \n",
    "\n",
    "# We will have to treat our values as floats for the model to build correctly\n",
    "model_6 = sm.OLS(Y4.astype(float), X4.astype(float)).fit()\n",
    " \n",
    "print_model_6 = model_6.summary()\n",
    "print(print_model_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### In this model, it looks like we only have one predictor that might be worth considering: \n",
    "\n",
    "1. Going out for enjoyment is associated with feeling substantially younger. Over three and a half years!\n",
    "\n",
    "##### Again, however, we have an extremely low R-squared value. So this model may not be indicitive of much.\n",
    "\n",
    "##### Next let's try a slightly different view of these same indicators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:         num_in_soc_net   R-squared:                       0.031\n",
      "Model:                            OLS   Adj. R-squared:                  0.030\n",
      "Method:                 Least Squares   F-statistic:                     47.12\n",
      "Date:                Wed, 11 Dec 2019   Prob (F-statistic):           5.68e-30\n",
      "Time:                        12:02:48   Log-Likelihood:                -7550.3\n",
      "No. Observations:                4456   AIC:                         1.511e+04\n",
      "Df Residuals:                    4452   BIC:                         1.513e+04\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==================================================================================\n",
      "                     coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "const              1.8675      0.103     18.048      0.000       1.665       2.070\n",
      "group_activity     0.3439      0.042      8.281      0.000       0.262       0.425\n",
      "go_out_enjoy       0.3154      0.048      6.515      0.000       0.221       0.410\n",
      "age_you_feel       0.0009      0.001      0.655      0.512      -0.002       0.003\n",
      "==============================================================================\n",
      "Omnibus:                      289.415   Durbin-Watson:                   2.023\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              269.191\n",
      "Skew:                           0.542   Prob(JB):                     3.51e-59\n",
      "Kurtosis:                       2.475   Cond. No.                         372.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\halli_000\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2389: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# As before, specify the independent and dependent variables\n",
    "X5 = data_subset_4[['group_activity', 'go_out_enjoy', 'age_you_feel']]\n",
    "Y5 = data_subset_4['num_in_soc_net']\n",
    "\n",
    "# Add a constant using StatsModels\n",
    "X5 = sm.add_constant(X5) \n",
    "\n",
    "# We will have to treat our values as floats for the model to build correctly\n",
    "model_7 = sm.OLS(Y5.astype(float), X5.astype(float)).fit()\n",
    " \n",
    "print_model_7 = model_7.summary()\n",
    "print(print_model_7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### In this model, we may have two predictors worth considering, but neither are surprising: \n",
    "\n",
    "1. Going out for enjoyment is associated with a slightly bigger social network.\n",
    "2. Engaging in group activities is associated with a slightly bigger social network.\n",
    "\n",
    "Both of these are highly significant, which makes a lot of intuitive sense.\n",
    "\n",
    "##### In (many) other models not illustrated here it was generally found that the size of a social network was difficult to predict, especially using indicators of disability\n",
    "\n",
    "The relationships between different indicators of social engagement and well-being might be interesting in their own right, but they also may shed some light on this. It is possible taht understanding the relationships of these other variables to various indicators of disability, and then to each other, might helop build a model to effectively predict the size of a social network using disability. This is a great avenue for future study."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally, let's create some models that help us understand the relationships between a few measures of disability, a few indicators of social engagement, and a general indicator of psychological well-being.\n",
    "\n",
    "#### Let's try another set of 6 independent variables:\n",
    "\n",
    "group_activity: whether or not the individual ever participates in group activities.\n",
    "\n",
    "go_out_enjoy: whether or not the individual ever goes out for enjoyment\n",
    "\n",
    "num_in_soc_net: the number of people in the individual's social network\n",
    "\n",
    "hearing_aid_used: whether or not a hearing aid was used\n",
    "\n",
    "sppb_score: a simple physical performance battery score, an indicator of basic physical strength, balance, and mobility\n",
    "\n",
    "walk_score: the result of a physical test measuring ability to walk\n",
    "\n",
    "#### And one dependent variable:\n",
    "\n",
    "life_has_meaning: whether or not an individual feels that life has meaning\n",
    "\n",
    "##### We will subset our data, remove the observations with missing values, and then build the model with StatsModels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4147, 7)\n"
     ]
    }
   ],
   "source": [
    "# Just like before we will re-subset the data to ensure we have as many complete observations as possible\n",
    "data_subset_6 = data[['group_activity', 'go_out_enjoy', 'num_in_soc_net', 'hearing_aid_used',\n",
    "                     'sppb_score', 'walk_score', 'life_has_meaning']] \n",
    "\n",
    "# Next we need to get rid of incomplete observations\n",
    "# Convert -1 (the encoding for a missing value) to nan and then drop them\n",
    "data_subset_6 = data_subset_6.replace(-1, np.nan)\n",
    "data_subset_6 = data_subset_6.dropna()\n",
    "\n",
    "# Check that this has left us with a reasonable number of observations\n",
    "# In this case we have over 4k observations left\n",
    "print(data_subset_6.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:       life_has_meaning   R-squared:                       0.061\n",
      "Model:                            OLS   Adj. R-squared:                  0.060\n",
      "Method:                 Least Squares   F-statistic:                     44.94\n",
      "Date:                Wed, 11 Dec 2019   Prob (F-statistic):           1.52e-53\n",
      "Time:                        12:17:53   Log-Likelihood:                -2510.4\n",
      "No. Observations:                4147   AIC:                             5035.\n",
      "Df Residuals:                    4140   BIC:                             5079.\n",
      "Df Model:                           6                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "====================================================================================\n",
      "                       coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------\n",
      "const                1.4844      0.020     73.320      0.000       1.445       1.524\n",
      "group_activity      -0.0479      0.015     -3.243      0.001      -0.077      -0.019\n",
      "go_out_enjoy        -0.0622      0.018     -3.496      0.000      -0.097      -0.027\n",
      "num_in_soc_net      -0.0351      0.005     -6.708      0.000      -0.045      -0.025\n",
      "hearing_aid_used     0.0335      0.017      1.950      0.051      -0.000       0.067\n",
      "sppb_score          -0.0238      0.004     -5.780      0.000      -0.032      -0.016\n",
      "walk_score           0.0047      0.011      0.420      0.675      -0.017       0.027\n",
      "==============================================================================\n",
      "Omnibus:                     1594.876   Durbin-Watson:                   1.981\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             5152.069\n",
      "Skew:                           2.008   Prob(JB):                         0.00\n",
      "Kurtosis:                       6.699   Cond. No.                         26.6\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\halli_000\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2389: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# As before, specify the independent and dependent variables\n",
    "X6 = data_subset_6[['group_activity', 'go_out_enjoy', 'num_in_soc_net', 'hearing_aid_used',\n",
    "                   'sppb_score', 'walk_score']]\n",
    "Y6 = data_subset_6['life_has_meaning']\n",
    "\n",
    "# Add a constant using StatsModels\n",
    "X6 = sm.add_constant(X6)\n",
    "\n",
    "# We will have to treat our values as floats for the model to build correctly\n",
    "model_8 = sm.OLS(Y6.astype(float), X6.astype(float)).fit()\n",
    " \n",
    "print_model_8 = model_8.summary()\n",
    "print(print_model_8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### In this model, we may have five predictors worth considering: \n",
    "\n",
    "NOTE: life_has_meaning has three possible values; 1 (agree a lot), 2 (agree a little), 3 (agree not at all)\n",
    "\n",
    "1. Engaing in group activities is associated with a higher liklihood of believing that life has meaning.\n",
    "2. Going out for enjoyment is also associated with a higher liklihood of believing that life has meaning.\n",
    "3. So is having a larger social network.\n",
    "4. Using a hearing aid is associated with a lower likelihood of believing that life has meaning. This is technically not significant even at an alpha=0.05 level but it is extremely close; in my opiion, it warrants further attention.\n",
    "5. A high sppb score is associated with a higher liklihood of believing that life has meaning.\n",
    "\n",
    "##### This gives us a lot of interesting interactions to consider, but let's just try looking at a few of them for now.\n",
    "\n",
    "We will examine the potential interactions between go_out_enjoy (the predictor with the highest absolute coefficient), group_activity, and sppb_score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:       life_has_meaning   R-squared:                       0.051\n",
      "Model:                            OLS   Adj. R-squared:                  0.050\n",
      "Method:                 Least Squares   F-statistic:                     32.00\n",
      "Date:                Wed, 11 Dec 2019   Prob (F-statistic):           1.53e-43\n",
      "Time:                        13:03:56   Log-Likelihood:                -2531.9\n",
      "No. Observations:                4147   AIC:                             5080.\n",
      "Df Residuals:                    4139   BIC:                             5130.\n",
      "Df Model:                           7                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==========================================================================================================\n",
      "                                             coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------------------------\n",
      "Intercept                                  1.4214      0.027     51.845      0.000       1.368       1.475\n",
      "group_activity                             0.0613      0.064      0.962      0.336      -0.064       0.186\n",
      "sppb_score                                -0.0229      0.005     -4.521      0.000      -0.033      -0.013\n",
      "group_activity:sppb_score                 -0.0217      0.011     -1.923      0.055      -0.044       0.000\n",
      "go_out_enjoy                              -0.0645      0.036     -1.771      0.077      -0.136       0.007\n",
      "group_activity:go_out_enjoy               -0.1442      0.075     -1.922      0.055      -0.291       0.003\n",
      "sppb_score:go_out_enjoy                   -0.0003      0.006     -0.050      0.960      -0.012       0.012\n",
      "group_activity:sppb_score:go_out_enjoy     0.0247      0.012      1.997      0.046       0.000       0.049\n",
      "==============================================================================\n",
      "Omnibus:                     1637.441   Durbin-Watson:                   1.983\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             5463.220\n",
      "Skew:                           2.052   Prob(JB):                         0.00\n",
      "Kurtosis:                       6.844   Cond. No.                         160.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# We will continue to use the StatsModels formula API because the syntax is simpler\n",
    "model_9 = smf.ols(formula='life_has_meaning ~ group_activity * sppb_score * go_out_enjoy', \n",
    "                 data=data_subset_6).fit()\n",
    "\n",
    "print(model_9.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Only one of the interactions in this new model are significant, but two of them are close.\n",
    "\n",
    "The interaction between engaging in group activities and a high sppb score has a P-value of 0.55, and indicates that this interaction may be associated with a slightly higher liklihood of believing that life has meaning.\n",
    "\n",
    "The interaction between engaging in group activities and going out for enjoyment has the same P-value, but may be associated with a larger increase in liklihood of believing that life has meaning.\n",
    "\n",
    "The interaction between all three predictors considered in this model is (barely) significant at an alpha=0.05 level, but surprisingly, it's associated wih a slightly lower liklihood of believing that life has meaning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
